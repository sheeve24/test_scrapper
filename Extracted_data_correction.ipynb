{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fad1b91-c41b-4623-a4a1-e2fd520b8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned CSV saved as: highape_events_enriched_20250607_171657_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file (replace with your actual file path)\n",
    "df = pd.read_csv(\"highape_events_enriched_20250607_171657.csv\")\n",
    "\n",
    "# Fix \"artists\" column safely\n",
    "for idx, row in df.iterrows():\n",
    "    artists = row.get(\"artists\", \"\")\n",
    "    if pd.notna(artists):\n",
    "        artist_list = [a.strip().title() for a in str(artists).split(\",\") if a.strip()]\n",
    "        df.at[idx, \"artists\"] = \", \".join(artist_list)\n",
    "    else:\n",
    "        df.at[idx, \"artists\"] = \"\"\n",
    "\n",
    "# Save to a new cleaned file\n",
    "df.to_csv(\"highape_events_enriched_20250607_171657_cleaned.csv\", index=False)\n",
    "print(\"✅ Cleaned CSV saved as: highape_events_enriched_20250607_171657_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7bda425-3151-439a-bf44-9a166f2cd7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/3116040685.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"eventDuration\"] = duration\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# --- Fix Artists ---\u001b[39;00m\n\u001b[1;32m     46\u001b[0m artists \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martists\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m df\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martists\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, [a\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mtitle() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)]))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# --- Validate lat/lon ---\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Post-processing script to clean and enhance HighApe event data\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "CSV_INPUT_PATH = \"highape_events_enriched_20250607_171657_cleaned.csv\"\n",
    "OUTPUT_CSV_PATH = \"highape_events_cleaned.csv\"\n",
    "HTML_JSON_FOLDER = Path(\"./\")  # JSON files in current folder\n",
    "\n",
    "# === HELPERS ===\n",
    "def parse_datetime_and_duration(date_str):\n",
    "    try:\n",
    "        date_time_match = re.search(r'(\\d{1,2} \\w+)(?: - (\\d{1,2} \\w+))?(?: \\| (\\d{1,2}:\\d{2} [APMapm]{2}))?', date_str)\n",
    "        if not date_time_match:\n",
    "            return date_str, ''\n",
    "\n",
    "        start_date = date_time_match.group(1)\n",
    "        end_date = date_time_match.group(2) or start_date\n",
    "        time_str = date_time_match.group(3) or \"6:00 PM\"\n",
    "\n",
    "        now_year = datetime.now().year\n",
    "        start = datetime.strptime(f\"{start_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        end = datetime.strptime(f\"{end_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        duration_ms = int((end - start).total_seconds() * 1000)\n",
    "        iso_str = start.isoformat() + \"Z\"\n",
    "        return iso_str, duration_ms\n",
    "    except:\n",
    "        return date_str, ''\n",
    "\n",
    "def normalize_text(text):\n",
    "    return re.sub(r'[\\n\\r]+', ' ', str(text)).strip()\n",
    "\n",
    "# === MAIN PROCESS ===\n",
    "df = pd.read_csv(CSV_INPUT_PATH)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # --- Fix Date & Duration ---\n",
    "    fixed_date, duration = parse_datetime_and_duration(row.get(\"eventDateAndTime\", \"\"))\n",
    "    df.at[idx, \"eventDateAndTime\"] = fixed_date\n",
    "    df.at[idx, \"eventDuration\"] = duration\n",
    "\n",
    "    # --- Fix Artists ---\n",
    "    artists = row.get(\"artists\", \"\")\n",
    "    df.at[idx, \"artists\"] = ', '.join(filter(None, [a.strip().title() for a in artists.split(\",\")]))\n",
    "\n",
    "    # --- Validate lat/lon ---\n",
    "    if row.get(\"lat\", \"\").strip() in [\"\", \"0\"]:\n",
    "        df.at[idx, \"lat\"] = \"\"\n",
    "    if row.get(\"lon\", \"\").strip() in [\"\", \"0\"]:\n",
    "        df.at[idx, \"lon\"] = \"\"\n",
    "\n",
    "    # --- Normalize Description ---\n",
    "    df.at[idx, \"eventDescription\"] = normalize_text(row.get(\"eventDescription\", \"\"))\n",
    "\n",
    "    # --- Load JSON raw HTML for missing data recovery ---\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if json_path and Path(json_path).exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            html_data = json.load(f)\n",
    "            # TODO: Add smart field recovery logic if needed\n",
    "\n",
    "# === OUTPUT ===\n",
    "df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "print(f\"✅ Cleaned CSV saved to: {OUTPUT_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240e575a-db29-4e10-96f0-624e3a3239a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned CSV saved to: highape_events_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "CSV_INPUT_PATH = \"highape_events_enriched_20250607_171657_cleaned.csv\"\n",
    "OUTPUT_CSV_PATH = \"highape_events_cleaned.csv\"\n",
    "HTML_JSON_FOLDER = Path(\"./\")  # All JSON files expected in current folder\n",
    "\n",
    "# === HELPERS ===\n",
    "def parse_datetime_and_duration(date_str):\n",
    "    try:\n",
    "        date_time_match = re.search(r'(\\d{1,2} \\w+)(?: - (\\d{1,2} \\w+))?(?: \\| (\\d{1,2}:\\d{2} [APMapm]{2}))?', str(date_str))\n",
    "        if not date_time_match:\n",
    "            return date_str, np.nan\n",
    "\n",
    "        start_date = date_time_match.group(1)\n",
    "        end_date = date_time_match.group(2) or start_date\n",
    "        time_str = date_time_match.group(3) or \"6:00 PM\"\n",
    "\n",
    "        now_year = datetime.now().year\n",
    "        start = datetime.strptime(f\"{start_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        end = datetime.strptime(f\"{end_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        duration_ms = int((end - start).total_seconds() * 1000)\n",
    "        iso_str = start.isoformat() + \"Z\"\n",
    "        return iso_str, duration_ms\n",
    "    except:\n",
    "        return date_str, np.nan\n",
    "\n",
    "def normalize_text(text):\n",
    "    return re.sub(r'[\\n\\r]+', ' ', str(text)).strip()\n",
    "\n",
    "# === MAIN PROCESS ===\n",
    "df = pd.read_csv(CSV_INPUT_PATH)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # --- Fix Date & Duration ---\n",
    "    fixed_date, duration = parse_datetime_and_duration(row.get(\"eventDateAndTime\", \"\"))\n",
    "    df.at[idx, \"eventDateAndTime\"] = fixed_date\n",
    "    df.at[idx, \"eventDuration\"] = duration\n",
    "\n",
    "    # --- Fix Artists ---\n",
    "    artists = row.get(\"artists\", \"\")\n",
    "    if pd.notna(artists):\n",
    "        df.at[idx, \"artists\"] = ', '.join(filter(None, [a.strip().title() for a in str(artists).split(\",\")]))\n",
    "    else:\n",
    "        df.at[idx, \"artists\"] = \"\"\n",
    "\n",
    "    # --- Validate lat/lon ---\n",
    "    if str(row.get(\"lat\", \"\")).strip() in [\"\", \"0\"]:\n",
    "        df.at[idx, \"lat\"] = \"\"\n",
    "    if str(row.get(\"lon\", \"\")).strip() in [\"\", \"0\"]:\n",
    "        df.at[idx, \"lon\"] = \"\"\n",
    "\n",
    "    # --- Normalize Description ---\n",
    "    df.at[idx, \"eventDescription\"] = normalize_text(row.get(\"eventDescription\", \"\"))\n",
    "\n",
    "    # --- Load raw HTML JSON if needed (placeholder) ---\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if json_path and Path(json_path).exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            html_data = json.load(f)\n",
    "            # TODO: Use HTML if specific fields are missing\n",
    "            pass\n",
    "\n",
    "# === OUTPUT ===\n",
    "df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "print(f\"✅ Cleaned CSV saved to: {OUTPUT_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822806e7-0676-4e77-9fd9-03bb9b70e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "INPUT_CSV = \"highape_events_cleaned.csv\"\n",
    "OUTPUT_CSV = \"highape_events_final_enriched.csv\"\n",
    "\n",
    "# Helper: Normalize text\n",
    "def normalize_text(text):\n",
    "    return re.sub(r'[\\n\\r]+', ' ', str(text)).strip()\n",
    "\n",
    "# Helper: Build Plur JSON\n",
    "def build_plur_json(event):\n",
    "    def to_int(val): return int(val) if str(val).isdigit() else 0\n",
    "    def to_float(val): return float(val) if re.match(r'^-?\\d+(?:\\.\\d+)?$', str(val)) else None\n",
    "\n",
    "    return {\n",
    "        \"eventName\": event.get(\"eventName\", \"\"),\n",
    "        \"eventDescription\": event.get(\"eventDescription\", \"\"),\n",
    "        \"eventDateAndTime\": event.get(\"eventDateAndTime\", \"\"),\n",
    "        \"eventDuration\": to_int(event.get(\"eventDuration\", \"\")),\n",
    "        \"venue\": {\n",
    "            \"venueName\": event.get(\"venueName\", \"\"),\n",
    "            \"locality\": event.get(\"locality\", \"\"),\n",
    "            \"address\": event.get(\"address\", \"\"),\n",
    "            \"city\": event.get(\"city\", \"\"),\n",
    "            \"state\": event.get(\"state\", \"\"),\n",
    "            \"zipcode\": event.get(\"zipcode\", \"\"),\n",
    "            \"geolocation\": {\n",
    "                \"lat\": to_float(event.get(\"lat\", \"\")),\n",
    "                \"lon\": to_float(event.get(\"lon\", \"\"))\n",
    "            },\n",
    "            \"layout\": event.get(\"layout\", \"\")\n",
    "        },\n",
    "        \"highlightImageLinks\": [event.get(\"highlightImages\")] if event.get(\"highlightImages\") else [],\n",
    "        \"galleryImageLinks\": [event.get(\"highlightImages\")] if event.get(\"highlightImages\") else [],\n",
    "        \"ticketAmount\": to_int(event.get(\"ticketAmount\", \"\")),\n",
    "        \"ticketLink\": event.get(\"ticketLink\", \"\"),\n",
    "        \"supportedLanguages\": [\"English\"],\n",
    "        \"category\": event.get(\"category\", \"\"),\n",
    "        \"subCategory\": event.get(\"subCategory\", \"\"),\n",
    "        \"eventType\": event.get(\"eventType\", \"\"),\n",
    "        \"eventFeatures\": {\n",
    "            \"foodAvailable\": event.get(\"foodAvailable\", \"\") == \"Yes\",\n",
    "            \"smokingAllowed\": event.get(\"smokingAllowed\", \"\") == \"Yes\",\n",
    "            \"wheelchairAccess\": event.get(\"wheelchairAccess\", \"\") == \"Yes\",\n",
    "            \"parkingAvailable\": event.get(\"parkingAvailable\", \"\") == \"Yes\",\n",
    "            \"supportAvailable\": event.get(\"supportAvailable\", \"\") == \"Yes\",\n",
    "            \"petFriendly\": event.get(\"petFriendly\", False),\n",
    "            \"alcoholServed\": event.get(\"alcoholServed\", \"\") == \"Yes\",\n",
    "            \"minimumAge\": to_int(event.get(\"minimumAge\", \"\")),\n",
    "            \"ticketsAtVenue\": event.get(\"ticketsAtVenue\", \"\") == \"Yes\",\n",
    "            \"washroomAvailable\": event.get(\"washroomAvailable\", \"\") == \"Yes\",\n",
    "            \"danceFloorAvailable\": event.get(\"danceFloorAvailable\", \"\") == \"Yes\",\n",
    "            \"poolAvailable\": event.get(\"poolAvailable\", \"\") == \"Yes\"\n",
    "        },\n",
    "        \"artists\": [a.strip() for a in str(event.get(\"artists\", \"\")).split(\",\") if a.strip()],\n",
    "        \"sharableEventOgImageLink\": event.get(\"highlightImages\", \"\"),\n",
    "        \"attendeesCount\": to_int(event.get(\"attendeesCount\", \"\")),\n",
    "        \"likesCount\": 0,\n",
    "        \"joinChatDetails\": {\n",
    "            \"joinChatLink\": \"\",\n",
    "            \"provider\": \"\",\n",
    "            \"isEnabled\": False\n",
    "        },\n",
    "        \"policyAndConditions\": str(event.get(\"policyAndConditions\", \"\")).split(\"\\n\") if event.get(\"policyAndConditions\") else [],\n",
    "        \"frequentlyAskedQuestions\": []\n",
    "    }\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Iterate over rows and enrich missing data\n",
    "for idx, row in df.iterrows():\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if json_path and Path(json_path).exists():\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = json.load(f)\n",
    "            html = raw_data.get(\"rawHtml\", \"\")\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            # Fill missing description\n",
    "            if not row.get(\"eventDescription\"):\n",
    "                desc_node = soup.select_one(\"#desc .event-content-div\")\n",
    "                if desc_node:\n",
    "                    df.at[idx, \"eventDescription\"] = normalize_text(desc_node.get_text())\n",
    "\n",
    "            # Fill highlight image\n",
    "            if not row.get(\"highlightImages\"):\n",
    "                img_node = soup.select_one('#image_carousel_web img.img-background-events')\n",
    "                if img_node and img_node.get(\"src\"):\n",
    "                    df.at[idx, \"highlightImages\"] = img_node[\"src\"]\n",
    "\n",
    "    # Normalize and rebuild Plur_json_format\n",
    "    event_dict = df.loc[idx].to_dict()\n",
    "    plur_json = build_plur_json(event_dict)\n",
    "    df.at[idx, \"Plur_json_format\"] = json.dumps(plur_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save updated file\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"✅ Final enriched CSV saved as: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10396d81-d273-4dbe-960f-c1a4fb1eddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/2752220149.py:107: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"eventDuration\"] = str(duration)\n",
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/2752220149.py:116: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"supportedLanguages\"] = lang if lang else \"en\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned and enriched CSV saved to: highape_events_cleaned_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "CSV_INPUT_PATH = \"highape_events_cleaned.csv\"\n",
    "CSV_OUTPUT_PATH = \"highape_events_cleaned_fixed.csv\"\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "def build_plur_json(event):\n",
    "    def to_int(val): return int(val) if str(val).isdigit() else 0\n",
    "    def to_float(val): return float(val) if re.match(r'^-?\\d+(?:\\.\\d+)?$', str(val)) else None\n",
    "\n",
    "    return {\n",
    "        \"eventName\": event[\"eventName\"],\n",
    "        \"eventDescription\": event[\"eventDescription\"],\n",
    "        \"eventDateAndTime\": event[\"eventDateAndTime\"],\n",
    "        \"eventDuration\": to_int(event[\"eventDuration\"]),\n",
    "        \"venue\": {\n",
    "            \"venueName\": event[\"venueName\"],\n",
    "            \"locality\": event[\"locality\"],\n",
    "            \"address\": event[\"address\"],\n",
    "            \"city\": event[\"city\"],\n",
    "            \"state\": event[\"state\"],\n",
    "            \"zipcode\": event[\"zipcode\"],\n",
    "            \"geolocation\": {\n",
    "                \"lat\": to_float(event[\"lat\"]),\n",
    "                \"lon\": to_float(event[\"lon\"]),\n",
    "            },\n",
    "            \"layout\": event.get(\"layout\", \"\")\n",
    "        },\n",
    "        \"highlightImageLinks\": [event[\"highlightImages\"]] if event[\"highlightImages\"] else [],\n",
    "        \"galleryImageLinks\": [event[\"highlightImages\"]] if event[\"highlightImages\"] else [],\n",
    "        \"ticketAmount\": to_int(event[\"ticketAmount\"]),\n",
    "        \"ticketLink\": event[\"ticketLink\"],\n",
    "        \"supportedLanguages\": [\"en\"] if not event[\"supportedLanguages\"] else [event[\"supportedLanguages\"]],\n",
    "        \"category\": event[\"category\"],\n",
    "        \"subCategory\": event[\"subCategory\"],\n",
    "        \"eventType\": event[\"eventType\"],\n",
    "        \"eventFeatures\": {\n",
    "            \"foodAvailable\": event[\"foodAvailable\"] == \"Yes\",\n",
    "            \"smokingAllowed\": event[\"smokingAllowed\"] == \"Yes\",\n",
    "            \"wheelchairAccess\": event[\"wheelchairAccess\"] == \"Yes\",\n",
    "            \"parkingAvailable\": event[\"parkingAvailable\"] == \"Yes\",\n",
    "            \"supportAvailable\": event[\"supportAvailable\"] == \"Yes\",\n",
    "            \"petFriendly\": bool(event[\"petFriendly\"]),\n",
    "            \"alcoholServed\": event[\"alcoholServed\"] == \"Yes\",\n",
    "            \"minimumAge\": to_int(event[\"minimumAge\"]),\n",
    "            \"ticketsAtVenue\": event[\"ticketsAtVenue\"] == \"Yes\",\n",
    "            \"washroomAvailable\": event[\"washroomAvailable\"] == \"Yes\",\n",
    "            \"danceFloorAvailable\": event[\"danceFloorAvailable\"] == \"Yes\",\n",
    "            \"poolAvailable\": event[\"poolAvailable\"] == \"Yes\"\n",
    "        },\n",
    "        \"artists\": str(event[\"artists\"]).split(\", \") if event[\"artists\"] else [],\n",
    "        \"sharableEventOgImageLink\": event[\"highlightImages\"],\n",
    "        \"attendeesCount\": to_int(event[\"attendeesCount\"]),\n",
    "        \"likesCount\": 0,\n",
    "        \"joinChatDetails\": {\n",
    "            \"joinChatLink\": \"\",\n",
    "            \"provider\": \"\",\n",
    "            \"isEnabled\": False\n",
    "        },\n",
    "        \"policyAndConditions\": str(event[\"policyAndConditions\"]).split(\"\\n\") if event[\"policyAndConditions\"] else [],\n",
    "        \"frequentlyAskedQuestions\": []\n",
    "    }\n",
    "\n",
    "def parse_event_duration(date_str):\n",
    "    try:\n",
    "        pattern = r'(\\d{1,2} \\w+)(?: - (\\d{1,2} \\w+))?(?: \\| (\\d{1,2}:\\d{2} [APMapm]{2}))?'\n",
    "        match = re.search(pattern, date_str)\n",
    "        if not match:\n",
    "            return date_str, \"\"\n",
    "\n",
    "        start_date = match.group(1)\n",
    "        end_date = match.group(2) or start_date\n",
    "        time_str = match.group(3) or \"6:00 PM\"\n",
    "        now_year = datetime.now().year\n",
    "\n",
    "        start = datetime.strptime(f\"{start_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        end = datetime.strptime(f\"{end_date} {now_year} {time_str}\", \"%d %B %Y %I:%M %p\")\n",
    "        duration_ms = int((end - start).total_seconds() * 1000)\n",
    "        iso_str = start.isoformat() + \"Z\"\n",
    "        return iso_str, str(duration_ms)\n",
    "    except:\n",
    "        return date_str, \"\"\n",
    "\n",
    "# === MAIN PROCESS ===\n",
    "df = pd.read_csv(CSV_INPUT_PATH)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # === Clean venueName ===\n",
    "    venue = str(row.get(\"venueName\", \"\"))\n",
    "    for field in [\"locality\", \"city\", \"state\"]:\n",
    "        val = str(row.get(field, \"\"))\n",
    "        if val and val in venue:\n",
    "            venue = venue.replace(val, \"\").strip(\", \").strip()\n",
    "    df.at[idx, \"venueName\"] = venue\n",
    "\n",
    "    # === Fix missing eventDateAndTime + duration ===\n",
    "    date_raw = str(row.get(\"eventDateAndTime\", \"\"))\n",
    "    iso, duration = parse_event_duration(date_raw)\n",
    "    df.at[idx, \"eventDateAndTime\"] = iso\n",
    "    df.at[idx, \"eventDuration\"] = str(duration)\n",
    "\n",
    "    # === Fix ticketAmount ===\n",
    "    ticket_amt = row.get(\"ticketAmount\", \"\")\n",
    "    if isinstance(ticket_amt, str) and \"free\" in ticket_amt.lower():\n",
    "        df.at[idx, \"ticketAmount\"] = \"0\"\n",
    "\n",
    "    # === Fix supportedLanguages ===\n",
    "    lang = str(row.get(\"supportedLanguages\", \"\")).strip()\n",
    "    df.at[idx, \"supportedLanguages\"] = lang if lang else \"en\"\n",
    "\n",
    "    # === Fix artists formatting ===\n",
    "    artists = row.get(\"artists\", \"\")\n",
    "    if isinstance(artists, str):\n",
    "        df.at[idx, \"artists\"] = ', '.join([a.strip().title() for a in artists.split(\",\") if a.strip()])\n",
    "    else:\n",
    "        df.at[idx, \"artists\"] = \"\"\n",
    "\n",
    "    # === Load HTML from jsonFilePath and extract if needed ===\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if json_path and Path(json_path).exists():\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            soup = BeautifulSoup(data.get(\"rawHtml\", \"\"), \"html.parser\")\n",
    "\n",
    "            # Example enhancement: try recovering missing description\n",
    "            if not row.get(\"eventDescription\"):\n",
    "                desc_node = soup.select_one('#desc .event-content-div')\n",
    "                if desc_node:\n",
    "                    df.at[idx, \"eventDescription\"] = desc_node.get_text(strip=True)\n",
    "\n",
    "            # Example: parse highlight image\n",
    "            if not row.get(\"highlightImages\"):\n",
    "                img_tag = soup.select_one('#image_carousel_web img.img-background-events')\n",
    "                if img_tag:\n",
    "                    df.at[idx, \"highlightImages\"] = img_tag.get(\"src\", \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not process {json_path}: {e}\")\n",
    "\n",
    "    # === Rebuild Plur_json_format ===\n",
    "    event_dict = df.loc[idx].to_dict()\n",
    "    plur_json = build_plur_json(event_dict)\n",
    "    df.at[idx, \"Plur_json_format\"] = json.dumps(plur_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# === SAVE OUTPUT ===\n",
    "df.to_csv(CSV_OUTPUT_PATH, index=False)\n",
    "print(f\"✅ Cleaned and enriched CSV saved to: {CSV_OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124fc33a-79d4-44a5-8289-685e5eb5f497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'rawHtml' field is now readable in Sublime.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = \"/Users/shiv/Documents/Jupyter/HighApe/event_json_files/run_20250607_161335/event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86.json\"\n",
    "\n",
    "# Load and parse\n",
    "data = json.loads(Path(file_path).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Prettify only the rawHtml field\n",
    "if \"rawHtml\" in data:\n",
    "    data[\"rawHtml\"] = BeautifulSoup(data[\"rawHtml\"], \"html.parser\").prettify()\n",
    "\n",
    "# Overwrite the same file (no renaming)\n",
    "Path(file_path).write_text(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"✅ 'rawHtml' field is now readable in Sublime.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09aef7cc-35a3-486f-ab5d-006d92506b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ rawHtml has been formatted and saved inside the JSON.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Input file path\n",
    "file_path = \"/Users/shiv/Documents/Jupyter/HighApe/event_json_files/run_20250607_161335/event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86.json\"\n",
    "\n",
    "# Load JSON\n",
    "data = json.loads(Path(file_path).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Format rawHtml if it exists\n",
    "if \"rawHtml\" in data:\n",
    "    # Prettify the HTML content\n",
    "    soup = BeautifulSoup(data[\"rawHtml\"], \"html.parser\")\n",
    "    pretty_html = soup.prettify()\n",
    "    data[\"rawHtml\"] = pretty_html\n",
    "\n",
    "    # Save back to the same file (optional: create a backup)\n",
    "    Path(file_path).write_text(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "    print(\"✅ rawHtml has been formatted and saved inside the JSON.\")\n",
    "else:\n",
    "    print(\"❌ 'rawHtml' field not found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3403026-6418-44b1-904e-ce8a91022f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prettified HTML saved to: event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86_pretty.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw/minified HTML\n",
    "input_path = Path(\"/Users/shiv/Documents/Jupyter/HighApe/event_json_files/run_20250607_161335/event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86.html\")\n",
    "html_content = input_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Parse and prettify\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "pretty_html = soup.prettify()\n",
    "\n",
    "# Save as a new file (or overwrite if you want)\n",
    "output_path = Path(\"event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86_pretty.html\")\n",
    "output_path.write_text(pretty_html, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Prettified HTML saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d16ac7c-16d7-461a-9f50-4c00f3840988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/2016744970.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '560034' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"zipcode\"] = zip_match.group(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saving updated file with JSON-LD enhancements → highape_events_cleaned_with_jsonld.csv\n"
     ]
    }
   ],
   "source": [
    "# Script: Enhance HighApe Event CSV using JSON-LD in raw HTML\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "CSV_INPUT = \"highape_events_cleaned.csv\"\n",
    "CSV_OUTPUT = \"highape_events_cleaned_with_jsonld.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_INPUT)\n",
    "\n",
    "# --- Helpers ---\n",
    "def parse_iso_and_duration(start, end):\n",
    "    try:\n",
    "        start_dt = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt = datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return start_dt.isoformat() + \"Z\", int((end_dt - start_dt).total_seconds() * 1000)\n",
    "    except:\n",
    "        return start, ''\n",
    "\n",
    "def extract_jsonld_from_html(html):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        script_tags = soup.find_all('script', type='application/ld+json')\n",
    "        for tag in script_tags:\n",
    "            try:\n",
    "                data = json.loads(tag.text.strip())\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if item.get('@type') == 'Event':\n",
    "                            return item\n",
    "                elif data.get('@type') == 'Event':\n",
    "                    return data\n",
    "            except:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML: {e}\")\n",
    "    return None\n",
    "\n",
    "# --- Main enhancement loop ---\n",
    "for idx, row in df.iterrows():\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if not json_path or not Path(json_path).exists():\n",
    "        continue\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        html_json = json.load(f)\n",
    "        html = html_json.get(\"rawHtml\")\n",
    "        ld = extract_jsonld_from_html(html)\n",
    "\n",
    "    if ld:\n",
    "        if not row.get(\"eventName\"):\n",
    "            df.at[idx, \"eventName\"] = ld.get(\"name\", \"\")\n",
    "\n",
    "        if not row.get(\"highlightImages\"):\n",
    "            df.at[idx, \"highlightImages\"] = ld.get(\"image\", \"\")\n",
    "\n",
    "        loc = ld.get(\"location\", {})\n",
    "        if isinstance(loc, dict):\n",
    "            df.at[idx, \"venueName\"] = loc.get(\"name\", \"\")\n",
    "            df.at[idx, \"address\"] = loc.get(\"address\", \"\")\n",
    "\n",
    "            addr = loc.get(\"address\", \"\")\n",
    "            zip_match = re.search(r'\\b(\\d{6})\\b', addr)\n",
    "            if zip_match:\n",
    "                df.at[idx, \"zipcode\"] = zip_match.group(1)\n",
    "\n",
    "            parts = re.findall(r'[A-Za-z]+', addr)\n",
    "            if len(parts) >= 3:\n",
    "                df.at[idx, \"locality\"] = parts[-3]\n",
    "                df.at[idx, \"city\"] = parts[-2]\n",
    "                df.at[idx, \"state\"] = parts[-1]\n",
    "\n",
    "        start, end = ld.get(\"startDate\", \"\"), ld.get(\"endDate\", \"\")\n",
    "        iso, duration = parse_iso_and_duration(start, end)\n",
    "        df.at[idx, \"eventDateAndTime\"] = iso\n",
    "        df.at[idx, \"eventDuration\"] = duration\n",
    "\n",
    "        offers = ld.get(\"offers\", [])\n",
    "        if isinstance(offers, list) and offers:\n",
    "            try:\n",
    "                prices = [float(o.get(\"price\", 0)) for o in offers if o.get(\"price\")]\n",
    "                if prices:\n",
    "                    df.at[idx, \"ticketAmount\"] = int(min(prices))\n",
    "                df.at[idx, \"ticketLink\"] = offers[0].get(\"url\", \"\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        performers = ld.get(\"performer\", [])\n",
    "        if isinstance(performers, list):\n",
    "            names = [p.get(\"name\") for p in performers if p.get(\"name\")]\n",
    "            df.at[idx, \"artists\"] = \", \".join(names)\n",
    "\n",
    "        if not row.get(\"supportedLanguages\"):\n",
    "            df.at[idx, \"supportedLanguages\"] = \"English\"\n",
    "\n",
    "        # Rebuild Plur_json_format\n",
    "        from ast import literal_eval\n",
    "        def to_int(val): return int(val) if str(val).isdigit() else 0\n",
    "        def to_float(val): return float(val) if re.match(r'^-?\\d+(\\.\\d+)?$', str(val)) else None\n",
    "\n",
    "        plur_json = {\n",
    "            \"eventName\": df.at[idx, \"eventName\"],\n",
    "            \"eventDescription\": df.at[idx, \"eventDescription\"],\n",
    "            \"eventDateAndTime\": df.at[idx, \"eventDateAndTime\"],\n",
    "            \"eventDuration\": to_int(df.at[idx, \"eventDuration\"]),\n",
    "            \"venue\": {\n",
    "                \"venueName\": df.at[idx, \"venueName\"],\n",
    "                \"locality\": df.at[idx, \"locality\"],\n",
    "                \"address\": df.at[idx, \"address\"],\n",
    "                \"city\": df.at[idx, \"city\"],\n",
    "                \"state\": df.at[idx, \"state\"],\n",
    "                \"zipcode\": df.at[idx, \"zipcode\"],\n",
    "                \"geolocation\": {\n",
    "                    \"lat\": to_float(df.at[idx, \"lat\"]),\n",
    "                    \"lon\": to_float(df.at[idx, \"lon\"])\n",
    "                },\n",
    "                \"layout\": df.at[idx, \"layout\"]\n",
    "            },\n",
    "            \"highlightImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"galleryImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"ticketAmount\": to_int(df.at[idx, \"ticketAmount\"]),\n",
    "            \"ticketLink\": df.at[idx, \"ticketLink\"],\n",
    "            \"supportedLanguages\": [df.at[idx, \"supportedLanguages\"]],\n",
    "            \"category\": df.at[idx, \"category\"],\n",
    "            \"subCategory\": df.at[idx, \"subCategory\"],\n",
    "            \"eventType\": df.at[idx, \"eventType\"],\n",
    "            \"eventFeatures\": {\n",
    "                \"foodAvailable\": df.at[idx, \"foodAvailable\"] == \"Yes\",\n",
    "                \"smokingAllowed\": df.at[idx, \"smokingAllowed\"] == \"Yes\",\n",
    "                \"wheelchairAccess\": df.at[idx, \"wheelchairAccess\"] == \"Yes\",\n",
    "                \"parkingAvailable\": df.at[idx, \"parkingAvailable\"] == \"Yes\",\n",
    "                \"supportAvailable\": df.at[idx, \"supportAvailable\"] == \"Yes\",\n",
    "                \"petFriendly\": df.at[idx, \"petFriendly\"] in [\"Yes\", True],\n",
    "                \"alcoholServed\": df.at[idx, \"alcoholServed\"] == \"Yes\",\n",
    "                \"minimumAge\": to_int(df.at[idx, \"minimumAge\"]),\n",
    "                \"ticketsAtVenue\": df.at[idx, \"ticketsAtVenue\"] == \"Yes\",\n",
    "                \"washroomAvailable\": df.at[idx, \"washroomAvailable\"] == \"Yes\",\n",
    "                \"danceFloorAvailable\": df.at[idx, \"danceFloorAvailable\"] == \"Yes\",\n",
    "                \"poolAvailable\": df.at[idx, \"poolAvailable\"] == \"Yes\"\n",
    "            },\n",
    "            \"artists\": df.at[idx, \"artists\"].split(\", \") if isinstance(df.at[idx, \"artists\"], str) else [],\n",
    "            \"sharableEventOgImageLink\": df.at[idx, \"highlightImages\"],\n",
    "            \"attendeesCount\": to_int(df.at[idx, \"attendeesCount\"]),\n",
    "            \"likesCount\": 0,\n",
    "            \"joinChatDetails\": {\n",
    "                \"joinChatLink\": \"\",\n",
    "                \"provider\": \"\",\n",
    "                \"isEnabled\": False\n",
    "            },\n",
    "            \"policyAndConditions\": df.at[idx, \"policyAndConditions\"].split(\"\\n\") if isinstance(df.at[idx, \"policyAndConditions\"], str) else [],\n",
    "            \"frequentlyAskedQuestions\": []\n",
    "        }\n",
    "\n",
    "        df.at[idx, \"Plur_json_format\"] = json.dumps(plur_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save final CSV\n",
    "print(f\"✅ Saving updated file with JSON-LD enhancements → {CSV_OUTPUT}\")\n",
    "df.to_csv(CSV_OUTPUT, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5640609a-e558-42e7-98f6-e8cdc19c7d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/2061853277.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '560034' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"zipcode\"] = zip_match.group(1)\n",
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/2061853277.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Indoor' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"layout\"] = \"Indoor\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saving updated file with JSON-LD enhancements → highape_events_cleaned_with_jsonld.csv\n"
     ]
    }
   ],
   "source": [
    "# Script: Enhance HighApe Event CSV using JSON-LD in raw HTML\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "CSV_INPUT = \"highape_events_cleaned.csv\"\n",
    "CSV_OUTPUT = \"highape_events_cleaned_with_jsonld.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_INPUT)\n",
    "\n",
    "# --- Helpers ---\n",
    "def parse_iso_and_duration(start, end):\n",
    "    try:\n",
    "        start_dt = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt = datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return start_dt.isoformat() + \"Z\", int((end_dt - start_dt).total_seconds() * 1000)\n",
    "    except:\n",
    "        return start, ''\n",
    "\n",
    "def extract_jsonld_from_html(html):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        script_tags = soup.find_all('script', type='application/ld+json')\n",
    "        for tag in script_tags:\n",
    "            try:\n",
    "                data = json.loads(tag.text.strip())\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if item.get('@type') == 'Event':\n",
    "                            return item\n",
    "                elif data.get('@type') == 'Event':\n",
    "                    return data\n",
    "            except:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML: {e}\")\n",
    "    return None\n",
    "\n",
    "# --- Main enhancement loop ---\n",
    "for idx, row in df.iterrows():\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if not json_path or not Path(json_path).exists():\n",
    "        continue\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        html_json = json.load(f)\n",
    "        html = html_json.get(\"rawHtml\")\n",
    "        ld = extract_jsonld_from_html(html)\n",
    "\n",
    "    if ld:\n",
    "        if not row.get(\"eventName\"):\n",
    "            df.at[idx, \"eventName\"] = ld.get(\"name\", \"\")\n",
    "\n",
    "        if not row.get(\"highlightImages\"):\n",
    "            df.at[idx, \"highlightImages\"] = ld.get(\"image\", \"\")\n",
    "\n",
    "        loc = ld.get(\"location\", {})\n",
    "        if isinstance(loc, dict):\n",
    "            df.at[idx, \"venueName\"] = loc.get(\"name\", \"\")\n",
    "            df.at[idx, \"address\"] = loc.get(\"address\", \"\")\n",
    "\n",
    "            addr = loc.get(\"address\", \"\")\n",
    "            zip_match = re.search(r'\\b(\\d{6})\\b', addr)\n",
    "            if zip_match:\n",
    "                df.at[idx, \"zipcode\"] = zip_match.group(1)\n",
    "\n",
    "            parts = re.findall(r'[A-Za-z]+', addr)\n",
    "            if len(parts) >= 3:\n",
    "                df.at[idx, \"locality\"] = parts[-3]\n",
    "                df.at[idx, \"city\"] = parts[-2]\n",
    "                df.at[idx, \"state\"] = parts[-1]\n",
    "\n",
    "        start, end = ld.get(\"startDate\", \"\"), ld.get(\"endDate\", \"\")\n",
    "        iso, duration = parse_iso_and_duration(start, end)\n",
    "        df.at[idx, \"eventDateAndTime\"] = iso\n",
    "        df.at[idx, \"eventDuration\"] = duration\n",
    "\n",
    "        offers = ld.get(\"offers\", [])\n",
    "        if isinstance(offers, list) and offers:\n",
    "            try:\n",
    "                prices = [float(o.get(\"price\", 0)) for o in offers if o.get(\"price\")]\n",
    "                if prices:\n",
    "                    df.at[idx, \"ticketAmount\"] = int(min(prices))\n",
    "                df.at[idx, \"ticketLink\"] = offers[0].get(\"url\", \"\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        performers = ld.get(\"performer\", [])\n",
    "        if isinstance(performers, list):\n",
    "            names = [p.get(\"name\") for p in performers if p.get(\"name\")]\n",
    "            df.at[idx, \"artists\"] = \", \".join(names)\n",
    "\n",
    "        if not row.get(\"supportedLanguages\"):\n",
    "            df.at[idx, \"supportedLanguages\"] = \"English\"\n",
    "\n",
    "        df.at[idx, \"layout\"] = \"Indoor\"\n",
    "\n",
    "        # Rebuild Plur_json_format\n",
    "        from ast import literal_eval\n",
    "        def to_int(val): return int(val) if str(val).isdigit() else 0\n",
    "        def to_float(val): return float(val) if re.match(r'^-?\\d+(\\.\\d+)?$', str(val)) else None\n",
    "\n",
    "        plur_json = {\n",
    "            \"eventName\": df.at[idx, \"eventName\"],\n",
    "            \"eventDescription\": df.at[idx, \"eventDescription\"],\n",
    "            \"eventDateAndTime\": df.at[idx, \"eventDateAndTime\"],\n",
    "            \"eventDuration\": to_int(df.at[idx, \"eventDuration\"]),\n",
    "            \"venue\": {\n",
    "                \"venueName\": df.at[idx, \"venueName\"],\n",
    "                \"locality\": df.at[idx, \"locality\"],\n",
    "                \"address\": df.at[idx, \"address\"],\n",
    "                \"city\": df.at[idx, \"city\"],\n",
    "                \"state\": df.at[idx, \"state\"],\n",
    "                \"zipcode\": df.at[idx, \"zipcode\"],\n",
    "                \"geolocation\": {\n",
    "                    \"lat\": to_float(df.at[idx, \"lat\"]),\n",
    "                    \"lon\": to_float(df.at[idx, \"lon\"])\n",
    "                },\n",
    "                \"layout\": \"Indoor\"\n",
    "            },\n",
    "            \"highlightImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"galleryImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"ticketAmount\": to_int(df.at[idx, \"ticketAmount\"]),\n",
    "            \"ticketLink\": df.at[idx, \"ticketLink\"],\n",
    "            \"supportedLanguages\": [\"en\"],\n",
    "            \"category\": df.at[idx, \"category\"],\n",
    "            \"subCategory\": df.at[idx, \"subCategory\"],\n",
    "            \"eventType\": df.at[idx, \"eventType\"],\n",
    "            \"eventFeatures\": {\n",
    "                \"foodAvailable\": df.at[idx, \"foodAvailable\"] == \"Yes\",\n",
    "                \"smokingAllowed\": df.at[idx, \"smokingAllowed\"] == \"Yes\",\n",
    "                \"wheelchairAccess\": df.at[idx, \"wheelchairAccess\"] == \"Yes\",\n",
    "                \"parkingAvailable\": df.at[idx, \"parkingAvailable\"] == \"Yes\",\n",
    "                \"supportAvailable\": df.at[idx, \"supportAvailable\"] == \"Yes\",\n",
    "                \"petFriendly\": df.at[idx, \"petFriendly\"] in [\"Yes\", True],\n",
    "                \"alcoholServed\": df.at[idx, \"alcoholServed\"] == \"Yes\",\n",
    "                \"minimumAge\": to_int(df.at[idx, \"minimumAge\"]),\n",
    "                \"ticketsAtVenue\": df.at[idx, \"ticketsAtVenue\"] == \"Yes\",\n",
    "                \"washroomAvailable\": df.at[idx, \"washroomAvailable\"] == \"Yes\",\n",
    "                \"danceFloorAvailable\": df.at[idx, \"danceFloorAvailable\"] == \"Yes\",\n",
    "                \"poolAvailable\": df.at[idx, \"poolAvailable\"] == \"Yes\"\n",
    "            },\n",
    "            \"artists\": df.at[idx, \"artists\"].split(\", \") if isinstance(df.at[idx, \"artists\"], str) else [],\n",
    "            \"sharableEventOgImageLink\": df.at[idx, \"highlightImages\"],\n",
    "            \"attendeesCount\": to_int(df.at[idx, \"attendeesCount\"]),\n",
    "            \"likesCount\": 0,\n",
    "            \"joinChatDetails\": {\n",
    "                \"joinChatLink\": \"\",\n",
    "                \"provider\": \"\",\n",
    "                \"isEnabled\": False\n",
    "            },\n",
    "            \"policyAndConditions\": df.at[idx, \"policyAndConditions\"].split(\"\\n\") if isinstance(df.at[idx, \"policyAndConditions\"], str) else [],\n",
    "            \"frequentlyAskedQuestions\": []\n",
    "        }\n",
    "\n",
    "        df.at[idx, \"Plur_json_format\"] = json.dumps(plur_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save final CSV\n",
    "print(f\"✅ Saving updated file with JSON-LD enhancements → {CSV_OUTPUT}\")\n",
    "df.to_csv(CSV_OUTPUT, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "794aada3-fb6d-4193-b013-d450ad83e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/j213xtt16vv3th1zm4c3gc4m0000gn/T/ipykernel_83464/526712220.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '560034' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, \"zipcode\"] = zip_match.group(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saving updated file with JSON-LD enhancements → highape_events_cleaned_with_jsonld_updated.csv\n"
     ]
    }
   ],
   "source": [
    "# Script: Enhance HighApe Event CSV using JSON-LD in raw HTML\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "CSV_INPUT = \"highape_events_cleaned_with_jsonld.csv\"\n",
    "CSV_OUTPUT = \"highape_events_cleaned_with_jsonld_updated.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_INPUT)\n",
    "\n",
    "# --- Helpers ---\n",
    "def parse_iso_and_duration(start, end):\n",
    "    try:\n",
    "        start_dt = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n",
    "        end_dt = datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return start_dt.isoformat() + \"Z\", int((end_dt - start_dt).total_seconds() * 1000)\n",
    "    except:\n",
    "        return start, ''\n",
    "\n",
    "def extract_jsonld_from_html(html):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        script_tags = soup.find_all('script', type='application/ld+json')\n",
    "        for tag in script_tags:\n",
    "            try:\n",
    "                data = json.loads(tag.text.strip())\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if item.get('@type') == 'Event':\n",
    "                            return item\n",
    "                elif data.get('@type') == 'Event':\n",
    "                    return data\n",
    "            except:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML: {e}\")\n",
    "    return None\n",
    "\n",
    "# --- Main enhancement loop ---\n",
    "for idx, row in df.iterrows():\n",
    "    json_path = row.get(\"jsonFilePath\")\n",
    "    if not json_path or not Path(json_path).exists():\n",
    "        continue\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        html_json = json.load(f)\n",
    "        html = html_json.get(\"rawHtml\")\n",
    "        ld = extract_jsonld_from_html(html)\n",
    "\n",
    "    if ld:\n",
    "        if not row.get(\"eventName\"):\n",
    "            df.at[idx, \"eventName\"] = ld.get(\"name\", \"\")\n",
    "\n",
    "        if not row.get(\"highlightImages\"):\n",
    "            df.at[idx, \"highlightImages\"] = ld.get(\"image\", \"\")\n",
    "\n",
    "        loc = ld.get(\"location\", {})\n",
    "        if isinstance(loc, dict):\n",
    "            df.at[idx, \"venueName\"] = loc.get(\"name\", \"\")\n",
    "            df.at[idx, \"address\"] = loc.get(\"address\", \"\")\n",
    "\n",
    "            addr = loc.get(\"address\", \"\")\n",
    "            zip_match = re.search(r'\\b(\\d{6})\\b', addr)\n",
    "            if zip_match:\n",
    "                df.at[idx, \"zipcode\"] = zip_match.group(1)\n",
    "\n",
    "            parts = re.findall(r'[A-Za-z]+', addr)\n",
    "            if len(parts) >= 3:\n",
    "                df.at[idx, \"locality\"] = parts[-3]\n",
    "                df.at[idx, \"city\"] = parts[-2]\n",
    "                df.at[idx, \"state\"] = parts[-1]\n",
    "\n",
    "        start, end = ld.get(\"startDate\", \"\"), ld.get(\"endDate\", \"\")\n",
    "        iso, duration = parse_iso_and_duration(start, end)\n",
    "        df.at[idx, \"eventDateAndTime\"] = iso\n",
    "        df.at[idx, \"eventDuration\"] = duration\n",
    "\n",
    "        offers = ld.get(\"offers\", [])\n",
    "        if isinstance(offers, list) and offers:\n",
    "            all_prices = []\n",
    "            for offer in offers:\n",
    "                try:\n",
    "                    price = float(offer.get(\"price\", 0))\n",
    "                    all_prices.append(price)\n",
    "                except:\n",
    "                    continue\n",
    "            if all_prices:\n",
    "                df.at[idx, \"ticketAmount\"] = int(max(all_prices))\n",
    "            if offers[0].get(\"url\"):\n",
    "                df.at[idx, \"ticketLink\"] = offers[0].get(\"url\")\n",
    "\n",
    "        performers = ld.get(\"performer\", [])\n",
    "        if isinstance(performers, list):\n",
    "            names = [p.get(\"name\") for p in performers if p.get(\"name\")]\n",
    "            df.at[idx, \"artists\"] = \", \".join(names)\n",
    "\n",
    "        if not row.get(\"supportedLanguages\"):\n",
    "            df.at[idx, \"supportedLanguages\"] = \"English\"\n",
    "\n",
    "        df.at[idx, \"layout\"] = \"Indoor\"\n",
    "\n",
    "        # Rebuild Plur_json_format\n",
    "        from ast import literal_eval\n",
    "        def to_int(val): return int(val) if str(val).isdigit() else 0\n",
    "        def to_float(val): return float(val) if re.match(r'^-?\\d+(\\.\\d+)?$', str(val)) else None\n",
    "\n",
    "        plur_json = {\n",
    "            \"eventName\": df.at[idx, \"eventName\"],\n",
    "            \"eventDescription\": df.at[idx, \"eventDescription\"],\n",
    "            \"eventDateAndTime\": df.at[idx, \"eventDateAndTime\"],\n",
    "            \"eventDuration\": to_int(df.at[idx, \"eventDuration\"]),\n",
    "            \"venue\": {\n",
    "                \"venueName\": df.at[idx, \"venueName\"],\n",
    "                \"locality\": df.at[idx, \"locality\"],\n",
    "                \"address\": df.at[idx, \"address\"],\n",
    "                \"city\": df.at[idx, \"city\"],\n",
    "                \"state\": df.at[idx, \"state\"],\n",
    "                \"zipcode\": df.at[idx, \"zipcode\"],\n",
    "                \"geolocation\": {\n",
    "                    \"lat\": to_float(df.at[idx, \"lat\"]),\n",
    "                    \"lon\": to_float(df.at[idx, \"lon\"])\n",
    "                },\n",
    "                \"layout\": \"Indoor\"\n",
    "            },\n",
    "            \"highlightImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"galleryImageLinks\": [df.at[idx, \"highlightImages\"]] if df.at[idx, \"highlightImages\"] else [],\n",
    "            \"ticketAmount\": to_int(df.at[idx, \"ticketAmount\"]),\n",
    "            \"ticketLink\": df.at[idx, \"ticketLink\"],\n",
    "            \"supportedLanguages\": [\"en\"],\n",
    "            \"category\": df.at[idx, \"category\"],\n",
    "            \"subCategory\": df.at[idx, \"subCategory\"],\n",
    "            \"eventType\": df.at[idx, \"eventType\"],\n",
    "            \"eventFeatures\": {\n",
    "                \"foodAvailable\": df.at[idx, \"foodAvailable\"] == \"Yes\",\n",
    "                \"smokingAllowed\": df.at[idx, \"smokingAllowed\"] == \"Yes\",\n",
    "                \"wheelchairAccess\": df.at[idx, \"wheelchairAccess\"] == \"Yes\",\n",
    "                \"parkingAvailable\": df.at[idx, \"parkingAvailable\"] == \"Yes\",\n",
    "                \"supportAvailable\": df.at[idx, \"supportAvailable\"] == \"Yes\",\n",
    "                \"petFriendly\": df.at[idx, \"petFriendly\"] in [\"Yes\", True],\n",
    "                \"alcoholServed\": df.at[idx, \"alcoholServed\"] == \"Yes\",\n",
    "                \"minimumAge\": to_int(df.at[idx, \"minimumAge\"]),\n",
    "                \"ticketsAtVenue\": df.at[idx, \"ticketsAtVenue\"] == \"Yes\",\n",
    "                \"washroomAvailable\": df.at[idx, \"washroomAvailable\"] == \"Yes\",\n",
    "                \"danceFloorAvailable\": df.at[idx, \"danceFloorAvailable\"] == \"Yes\",\n",
    "                \"poolAvailable\": df.at[idx, \"poolAvailable\"] == \"Yes\"\n",
    "            },\n",
    "            \"artists\": df.at[idx, \"artists\"].split(\", \") if isinstance(df.at[idx, \"artists\"], str) else [],\n",
    "            \"sharableEventOgImageLink\": df.at[idx, \"highlightImages\"],\n",
    "            \"attendeesCount\": to_int(df.at[idx, \"attendeesCount\"]),\n",
    "            \"likesCount\": 0,\n",
    "            \"joinChatDetails\": {\n",
    "                \"joinChatLink\": \"\",\n",
    "                \"provider\": \"\",\n",
    "                \"isEnabled\": False\n",
    "            },\n",
    "            \"policyAndConditions\": df.at[idx, \"policyAndConditions\"].split(\"\\n\") if isinstance(df.at[idx, \"policyAndConditions\"], str) else [],\n",
    "            \"frequentlyAskedQuestions\": []\n",
    "        }\n",
    "\n",
    "        df.at[idx, \"Plur_json_format\"] = json.dumps(plur_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save final CSV\n",
    "print(f\"✅ Saving updated file with JSON-LD enhancements → {CSV_OUTPUT}\")\n",
    "df.to_csv(CSV_OUTPUT, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "933f78bb-e60f-4a11-b8f3-6164a08117ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artists': [],\n",
      " 'attendeesCount': 0,\n",
      " 'category': 'Dj Night,offers,ladies night,Club Margarita '\n",
      "             ',Goa,Clubmargarita,friday,Free Entry',\n",
      " 'eventDateAndTime': '2025-06-13T18:00:00',\n",
      " 'eventDescription': 'Highlights DJ Night Nonstop Music Great Ambience Ladies '\n",
      "                     'Night Mouthwatering Appetizers Cocktails and Mocktails '\n",
      "                     'Friday Fever at Club Margarita is the ultimate ignition '\n",
      "                     'to your weekend. Step into a world pulsing with energy, '\n",
      "                     'where the lights burn brighter and the beats hit harder. '\n",
      "                     'The air is electric with anticipation, as every corner '\n",
      "                     'of the club invites you to dance, mingle, and indulge. '\n",
      "                     'This is where glamour meets rhythm, where bold fashion '\n",
      "                     'and fiery spirits set the tone for an unforgettable nig',\n",
      " 'eventDuration': 23400000,\n",
      " 'eventFeatures': {'alcoholServed': True,\n",
      "                   'danceFloorAvailable': True,\n",
      "                   'foodAvailable': True,\n",
      "                   'minimumAge': 0,\n",
      "                   'parkingAvailable': False,\n",
      "                   'petFriendly': False,\n",
      "                   'poolAvailable': False,\n",
      "                   'smokingAllowed': False,\n",
      "                   'supportAvailable': False,\n",
      "                   'ticketsAtVenue': False,\n",
      "                   'washroomAvailable': False,\n",
      "                   'wheelchairAccess': False},\n",
      " 'eventName': 'Friday Fever',\n",
      " 'eventType': nan,\n",
      " 'frequentlyAskedQuestions': [],\n",
      " 'galleryImageLinks': ['https://res.cloudinary.com/https-highape-com/image/upload/q_auto:eco,f_auto,h_530/v1747728886/wfszhl95pey9au5wnnmi.jpg'],\n",
      " 'highlightImageLinks': ['https://res.cloudinary.com/https-highape-com/image/upload/q_auto:eco,f_auto,h_530/v1747728886/wfszhl95pey9au5wnnmi.jpg'],\n",
      " 'joinChatDetails': {'isEnabled': False, 'joinChatLink': '', 'provider': ''},\n",
      " 'likesCount': 0,\n",
      " 'policyAndConditions': ['By signing in, you agree to our',\n",
      "                         'Terms of Usage',\n",
      "                         'By signing in, you agree to our',\n",
      "                         'Terms of Usage',\n",
      "                         'By signing in, you agree to our',\n",
      "                         'Terms of Usage',\n",
      "                         'Details will be used for sending ticket '\n",
      "                         'confirmation.'],\n",
      " 'sharableEventOgImageLink': 'https://res.cloudinary.com/https-highape-com/image/upload/q_auto:eco,f_auto,h_530/v1747728886/wfszhl95pey9au5wnnmi.jpg',\n",
      " 'subCategory': nan,\n",
      " 'supportedLanguages': ['en'],\n",
      " 'ticketAmount': 0.0,\n",
      " 'ticketLink': 'https://tickets.highape.com/?event_name=friday-fever-zPrJ6g8erl&amp;city=goa&amp;source=allevents_list&amp;module_type=event',\n",
      " 'ticketOptions': [{'currency': 'INR',\n",
      "                    'price': 0.0,\n",
      "                    'type': 'Ladies',\n",
      "                    'url': 'https://tickets.highape.com/?event_name=friday-fever-zPrJ6g8erl&amp;city=goa&amp;source=allevents_list&amp;module_type=event'},\n",
      "                   {'currency': 'INR',\n",
      "                    'price': 0.0,\n",
      "                    'type': 'Couples',\n",
      "                    'url': 'https://tickets.highape.com/?event_name=friday-fever-zPrJ6g8erl&amp;city=goa&amp;source=allevents_list&amp;module_type=event'},\n",
      "                   {'currency': 'INR',\n",
      "                    'price': 0.0,\n",
      "                    'type': 'Stags',\n",
      "                    'url': 'https://tickets.highape.com/?event_name=friday-fever-zPrJ6g8erl&amp;city=goa&amp;source=allevents_list&amp;module_type=event'},\n",
      "                   {'currency': 'INR',\n",
      "                    'price': 0.0,\n",
      "                    'type': 'Entry',\n",
      "                    'url': 'https://tickets.highape.com/?event_name=friday-fever-zPrJ6g8erl&amp;city=goa&amp;source=allevents_list&amp;module_type=event'}],\n",
      " 'venue': {'address': 'Colva Beach Rd, Colva, Goa 403708, India',\n",
      "           'city': 'Colva',\n",
      "           'geolocation': {'lat': None, 'lon': None},\n",
      "           'layout': 'Indoor',\n",
      "           'locality': 'Colva Beach Rd',\n",
      "           'state': 'Goa 403708',\n",
      "           'venueName': 'Club Margarita',\n",
      "           'zipcode': '403708'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# === Load file ===\n",
    "with open(\"/Users/shiv/Documents/Jupyter/HighApe/event_json_files/run_20250607_161335/event_1bdd4ba4-1d6b-4c21-beb8-19482f712e86.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "soup = BeautifulSoup(raw[\"rawHtml\"], \"html.parser\")\n",
    "\n",
    "# === Try to extract JSON-LD ===\n",
    "ld_json_script = soup.find(\"script\", {\"type\": \"application/ld+json\"})\n",
    "schema = {}\n",
    "try:\n",
    "    ld_data = json.loads(ld_json_script.string)\n",
    "    schema = ld_data[0] if isinstance(ld_data, list) else ld_data\n",
    "except:\n",
    "    schema = {}\n",
    "\n",
    "# === Extract image links ===\n",
    "image_links = [a['href'] for a in soup.select('a[data-fancybox=\"event_images\"]') if a.get(\"href\")]\n",
    "\n",
    "# === Extract meta info as fallback ===\n",
    "meta = lambda prop: soup.find(\"meta\", attrs={\"property\": prop}) or soup.find(\"meta\", attrs={\"name\": prop})\n",
    "meta_title = meta(\"og:title\")[\"content\"] if meta(\"og:title\") else \"\"\n",
    "meta_desc = meta(\"og:description\")[\"content\"] if meta(\"og:description\") else \"\"\n",
    "meta_keywords = meta(\"keywords\")[\"content\"] if meta(\"keywords\") else \"\"\n",
    "meta_image = meta(\"og:image\")[\"content\"] if meta(\"og:image\") else \"\"\n",
    "\n",
    "# === Dates ===\n",
    "start = schema.get(\"startDate\", \"\")\n",
    "end = schema.get(\"endDate\", \"\")\n",
    "duration = 0\n",
    "try:\n",
    "    duration = int((datetime.fromisoformat(end) - datetime.fromisoformat(start)).total_seconds() * 1000)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# === Location parsing ===\n",
    "address = schema.get(\"location\", {}).get(\"address\", \"\")\n",
    "venue_name = schema.get(\"location\", {}).get(\"name\", \"\")\n",
    "zipcode = re.search(r\"\\b\\d{6}\\b\", address)\n",
    "zipcode = zipcode.group(0) if zipcode else \"\"\n",
    "parts = address.split(\",\")\n",
    "city = parts[-3].strip() if len(parts) >= 3 else \"\"\n",
    "state = parts[-2].strip() if len(parts) >= 2 else \"\"\n",
    "locality = parts[-4].strip() if len(parts) >= 4 else \"\"\n",
    "\n",
    "# === Ticket info ===\n",
    "offers = schema.get(\"offers\", [])\n",
    "ticket_options = []\n",
    "prices = []\n",
    "for o in offers:\n",
    "    try:\n",
    "        p = float(o.get(\"price\", \"0\"))\n",
    "        prices.append(p)\n",
    "        ticket_options.append({\n",
    "            \"type\": o.get(\"name\", \"\"),\n",
    "            \"price\": p,\n",
    "            \"currency\": o.get(\"priceCurrency\", \"INR\"),\n",
    "            \"url\": o.get(\"url\", \"\")\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "ticket_amount = max(prices) if prices else 0\n",
    "\n",
    "# === Policy parsing ===\n",
    "policies = [p.get_text(strip=True) for p in soup.select(\"div#tnc_text p, .tnc_text p\")]\n",
    "\n",
    "# === Final Output ===\n",
    "event = {\n",
    "    \"eventName\": schema.get(\"name\", meta_title),\n",
    "    \"eventDescription\": schema.get(\"description\", meta_desc),\n",
    "    \"eventDateAndTime\": datetime.fromisoformat(start).isoformat() if start else \"\",\n",
    "    \"eventDuration\": duration,\n",
    "    \"venue\": {\n",
    "        \"venueName\": venue_name,\n",
    "        \"locality\": locality,\n",
    "        \"address\": address,\n",
    "        \"city\": city,\n",
    "        \"state\": state,\n",
    "        \"zipcode\": zipcode,\n",
    "        \"geolocation\": {\"lat\": None, \"lon\": None},\n",
    "        \"layout\": \"Indoor\"\n",
    "    },\n",
    "    \"highlightImageLinks\": [image_links[0]] if image_links else [],\n",
    "    \"galleryImageLinks\": image_links,\n",
    "    \"ticketAmount\": ticket_amount,\n",
    "    \"ticketOptions\": ticket_options,\n",
    "    \"ticketLink\": ticket_options[0][\"url\"] if ticket_options else \"\",\n",
    "    \"supportedLanguages\": [\"en\"],\n",
    "    \"category\": meta_keywords,\n",
    "    \"subCategory\": float(\"nan\"),\n",
    "    \"eventType\": float(\"nan\"),\n",
    "    \"eventFeatures\": {\n",
    "        \"foodAvailable\": bool(re.search(r\"food|appetizer\", meta_desc, re.I)),\n",
    "        \"smokingAllowed\": False,\n",
    "        \"wheelchairAccess\": False,\n",
    "        \"parkingAvailable\": bool(re.search(r\"parking\", meta_desc, re.I)),\n",
    "        \"supportAvailable\": False,\n",
    "        \"petFriendly\": False,\n",
    "        \"alcoholServed\": bool(re.search(r\"alcohol|cocktail\", meta_desc, re.I)),\n",
    "        \"minimumAge\": 0,\n",
    "        \"ticketsAtVenue\": False,\n",
    "        \"washroomAvailable\": False,\n",
    "        \"danceFloorAvailable\": bool(re.search(r\"dance\", meta_desc, re.I)),\n",
    "        \"poolAvailable\": False\n",
    "    },\n",
    "    \"artists\": [p.get(\"name\") for p in schema.get(\"performer\", [])] if \"performer\" in schema else [],\n",
    "    \"sharableEventOgImageLink\": schema.get(\"image\", meta_image),\n",
    "    \"attendeesCount\": 0,\n",
    "    \"likesCount\": 0,\n",
    "    \"joinChatDetails\": {\n",
    "        \"joinChatLink\": \"\",\n",
    "        \"provider\": \"\",\n",
    "        \"isEnabled\": False\n",
    "    },\n",
    "    \"policyAndConditions\": policies,\n",
    "    \"frequentlyAskedQuestions\": []\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "429c5dff-5f00-47e8-a047-7778625583de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (118699560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    const fs = require('fs');\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
